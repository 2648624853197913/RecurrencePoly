\documentclass[a4paper,12pt]{article}

\include{preamble}

\begin{document}

\begin{definition}
Let $A \in \mathbb{R}^{n\times n}$and $v \in \mathbb{R}^n$. The $A$-cyclic subspace generated by $v$ is the subspace which is generated by the vectors $v, Av, A^2v, \ldots, A^nv$ (i.e. the smallest $A$-invariant subspace containing $v$). This subspace is denoted by $Z(v,A)$.
\end{definition}

Let $k\in\mathbb{N}$ be the smallest number such that $A^kv = \sum_{i=0}^{k-1}\beta_i A^i v$ is a linear combination of $v,Av,\ldots,A^{k-1}v$. Then the characteristic polynomial of $A$ restricted to $Z(v,A)$ is given by
$$p(x) = x^k - \sum_{i=0}^{k-1}\beta_ix^i.$$

\begin{claim}
Let $A \in \mathbb{R}^{n\times n}$ symmetric, $v \in \mathbb{R}^n$ and $\lambda \in \mathbb{R}$ an eigenvalue of $A$. Then $\lambda$ is an eigenvalue of $A$ restricted to $Z(v,A)$ if and only if there exists an eigenvector $w \in V_\lambda(A)$ with $\langle v, w \rangle \neq 0$. Furthermore, the multiplicity of each eigenvalue of $A$ restricted to $Z(v, A)$ is equal to 1.
\end{claim}

\begin{proof}
Assume $\langle v, w \rangle = 0$ for all $w \in V_\lambda(A)$. Then it holds that for all $i = 0, \ldots, k-1$:
$$ \langle w, A^i v \rangle = \langle A^i w, v \rangle = \lambda^i \langle w, v \rangle = 0.$$
Hence, all $w\in V_\lambda(A)$ are orthogonal to all vectors in $Z(v, A)$ and in particular $Z(v,A)$ can not contain an eigenvector $w \in V_\lambda(A)$.

Conversely, assume $\langle v, w \rangle \neq 0$ for some $w\in V_\lambda(A)$. Let $k = \textrm{dim}(Z(v,A))$ and write
$$A^k v = \sum_{i=0}^{k-1} \beta_iA^i v.$$
If $\lambda = 0$, it holds that for all $i \in \mathbb{N}_+$:
$$\langle w, A^i v \rangle = \langle A^i w, v \rangle = 0.$$
In particular, this implies
\begin{align*}
0 &= \langle A^kv - \sum_{i=0}^{k-1}\beta_iA^iv, w \rangle\\
&= \beta_0\langle v, w\rangle.
\end{align*}
Since $\langle v, w \rangle \neq 0$, this implies $\beta_0 = 0$ and hence $x$ is a factor of the characteristic polynomial of $A$.\\
If $\lambda \neq 0$, it holds that $\langle w, A^kv \rangle = \lambda^k \langle w, v \rangle$ and hence
$$
\lambda^{-k} = \frac {\langle v, w \rangle}{\langle A^kv, w \rangle}.
$$
On the other hand, we can conclude
$$
\langle w, A^k v \rangle = \langle w, \sum_{i=0}^{k-1}\beta_iA^iv\rangle = \sum_{i=0}^{k-1}\beta_i\lambda^i\langle v, w\rangle.
$$
Therefore, it holds that
$$
\sum_{i=0}^{k-1}\beta_i\lambda^i = \frac {\langle A^k, w \rangle}{\langle v, w \rangle}
$$
and from this it follows that
$$
\lambda^{-k} \cdot \sum_{i=0}^{k-1}\beta_i\lambda^i = 1.
$$

Now, define for $i = 0, \ldots, k-1$ the coefficients $\alpha_i$ by
$$ \alpha_i \coloneqq \frac 1 \lambda \left(\beta_i + \alpha_{i-1}\right) \text{ (where $\alpha_{-1} = 0$)} $$
and define the vector $w'$ by
$$w' \coloneqq \sum_{i=0}^{k-1}\alpha_i A^i v.$$
The vector $w'$ is an eigenvector of $A$ with respect to the eigenvalue $\lambda$, if and only if $\alpha_{k-1} = 1$. Indeed, from the definition of $w'$ it follows
\begin{align*}
Aw' &= A \left(\sum_{i=0}^{k-1}\alpha_i A^i v\right)\\
&= \sum_{i=1}^{k-1} \alpha_{i-1}A^iv + \sum_{i=0}^{k-1}\beta_iA^iv\\
&= \sum_{i=0}^{k-1} \left(\alpha_{i-1} + \beta_i\right)A^iv\\
&= \lambda \sum_{i=0}^{k-1} \alpha_iA^iv\\
&= \lambda w'.
\end{align*}
From the recursive definition of the $\alpha_i$, we can inductively show, that
$$ \alpha_{k-1} = \lambda^{-k}  \cdot \sum_{i=0}^{k-1}\beta_i\lambda^i = 1, $$
and hence the desired result follows.

It is still left to show that each eigenspace of $A$ restricted to $Z(v,A)$ is indeed one-dimensional.
This can easily be seen from the fact, that if the equation $Aw = \lambda w$ is fulfilled for some $w = \sum_{i=0}^{k-1}\alpha_iA^iv$, then the coefficients $\alpha_i$ are (wlog $\alpha_{k-1} = 1$) determined uniquely by
$$ \alpha_i \coloneqq \frac 1 \lambda \left(\beta_i + \alpha_{i-1}\right) \text{ (where $\alpha_{-1} = 0$)}, $$
if $\lambda \neq 0$, resp. by
$$
\alpha_i= -\beta_{i+1}, \alpha_{k-1} = 1
$$
if $\lambda = 0$.

Note that if $\alpha_{k-1} = 0$, the vector $\sum_{i=0}^{k-1}\alpha_iA^iv$ can not be an eigenvector of $A$.

\end{proof}

\begin{cor}
Let $G$ be an undirected graph with adjacency matrix $A$. Then the recurrence polynomial $\varrho_G$ is exactly the characteristic polynomial of $A$, restricted to the $A$-cyclic subspace generated by $v = (1, \ldots, 1)^T$.
\end{cor}
%\bibliography{references}

\begin{cor}
Let $G$ be a graph with recurrence polynomial of degree at most two. Then it holds that $$w_rw_s \le w_0w_{r+s}$$
with equality if and only if the graph is 1-recurrent.
\end{cor}

\begin{proof}
Let $A$ be the adjacency matrix of $G$ and let $v = (1, \ldots, 1)^T$.
Note that it suffices to show that $\varrho_G(\overline{d}) \le 0$, where $\overline{d} = \frac{v^TAv}n = \frac{\langle v,Av \rangle}{\langle v,v\rangle}$ is the average degree of $G$.
From the Cauchy-Schwarz inequality it follows that
$$
\overline{d}^2 = \frac {\langle v, Av \rangle^2}{\langle v,v\rangle^2} \le \frac {\langle v,v\rangle \cdot \langle Av,Av\rangle}{\langle v,v\rangle^2} = \frac {\langle v,A^2v\rangle}{\langle v,v\rangle},
$$
with equality if and only if $v$ and $Av$ are linearly dependent (i.e. $\varrho_G$ is of degree 1).
Let $A^2v = \beta_0v + \beta_1Av$ and hence $\varrho_G(x) = x^2-\beta_1x-\beta_0$. Then we can conclude
\begin{align*}
\varrho_G(\overline{d}) &= \overline{d}^2-\beta_1\overline{d} - \beta_0\\
&\le \frac {\langle v,A^2v \rangle}{\langle v,v\rangle} - \frac {\beta_1 \langle v,Av \rangle}{\langle v,v\rangle} - \frac{\beta_0 \langle v,v\rangle}{\langle v,v\rangle}\\
&= \frac {\langle v,A^2v - \beta_1Av-\beta_0v\rangle}{\langle v,v\rangle}\\
&= 0.
\end{align*}
\end{proof}

\end{document}